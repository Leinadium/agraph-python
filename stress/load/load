#!/usr/bin/env python2.6
# -*- coding: utf-8 -*-

##***** BEGIN LICENSE BLOCK *****
##Version: MPL 1.1
##
##The contents of this file are subject to the Mozilla Public License Version
##1.1 (the "License"); you may not use this file except in compliance with
##the License. You may obtain a copy of the License at
##http:##www.mozilla.org/MPL/
##
##Software distributed under the License is distributed on an "AS IS" basis,
##WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
##for the specific language governing rights and limitations under the
##License.
##
##The Original Code is the AllegroGraph Java Client interface.
##
##The Original Code was written by Franz Inc.
##Copyright (C) 2006 Franz Inc.  All Rights Reserved.
##
##***** END LICENSE BLOCK *****

"""
Usage: load [dir_or_file [process_count]]

load will walk the directory (the current directory is default)
or read the file specified for the list of .nt, .owl, and/or
.rdf files and load them using the number of processes (or
4 processes by default). You must use absolute pathnames in
the file list. No blank lines are allowed.

If the environment variable AGRAPH_HOST exists is set to anything other
than localhost, the script accesses the files locally and posts the
contents in the request. Otherwise, it uses server-side loads if on the
same machine as the server.
"""

from __future__ import with_statement
from multiprocessing import Process
from Queue import Empty
from datetime import datetime
import os, sys, time, traceback

from franz.openrdf.sail.allegrographserver import AllegroGraphServer
from franz.openrdf.repository.repository import Repository
from franz.openrdf.vocabulary import XMLSchema

LOCALHOST = 'localhost'
AG_HOST = os.environ.get('AGRAPH_HOST', LOCALHOST)
AG_PORT = int(os.environ.get('AGRAPH_PORT', '10035'))
AG_ONSERVER = AG_HOST == LOCALHOST
PROG = sys.argv[0]

# The work queue
work = None

def buggy_version():
    """There is a bug in Python versions <= 2.6.2"""
    return map(int, sys.version.split()[0].split('.')) <= [2, 6, 2]

if buggy_version():
    from multiprocessing.queues import JoinableQueue as BadJoinableQueue
    class JoinableQueue(BadJoinableQueue):
        def put(self, obj, block=True, timeout=None):
            assert not self._closed
            if not self._sem.acquire(block, timeout):
                raise Full

            self._notempty.acquire()
            self._cond.acquire()
            try:
                if self._thread is None:
                    self._start_thread()
                self._buffer.append(obj)
                self._unfinished_tasks.release()
                self._notempty.notify()
            finally:
                self._cond.release()
                self._notempty.release()
else:
    from multiprocessing import JoinableQueue

def connect(access_mode=Repository.OPEN):
    """
    Connect is called to connect to a store.
    """
    server = AllegroGraphServer(AG_HOST, AG_PORT, 'test', 'xyzzy')
    catalog = server.openCatalog('tests')
    repository = catalog.getRepository('load_test', access_mode)
    repository.initialize()
    return repository.getConnection()

def load_files(proc_num):
    """
    load_files does the work of the child processes.
    """
    conn = connect()
    conn.openSession(True)

    def dequeue():
        try:
            return work.get()
        except Empty:
            return None

    filename = dequeue()

    count = 0
    errors = 0
    while filename:
        context = conn.createLiteral(filename, datatype=XMLSchema.STRING)
        
        if count % 100 == 0:
            print '%s(%d) [%s]: Processed %d files so far...' % (
                PROG, proc_num, datetime.now(), count)
            sys.stdout.flush()
            
        try:
            conn.addFile(filename, context=context, serverSide=AG_ONSERVER)
            count += 1
        except Exception:
            print '%s(%d) [%s]: Error processing file %s...' % (
                PROG, proc_num, datetime.now(), filename)
            sys.stdout.flush()
            errors += 1
            traceback.print_exc()
        work.task_done()
        filename = dequeue()

    work.task_done()

    conn.closeSession()
    conn.close()

    print "%s(%d) [%s]: Process finished, %d files loaded, " \
        "%d loading errors." % (PROG, proc_num, datetime.now(), count, errors)
    sys.stdout.flush()

def main():
    """
    The parent main process.
    """
    global work

    try:
        path = sys.argv[1]
        if not os.path.exists(path):
            print __doc__
            sys.exit(1)
        is_dir = os.path.isdir(path)
    except IndexError:
        path = '.'
        is_dir = True

    try:
        proc_count = int(sys.argv[2])
    except IndexError:
        proc_count = 4

    # Renewing the repository
    print '%s [%s]: Renewing the repository.' % (PROG, datetime.now())
    conn = connect(Repository.RENEW)
    triples = conn.size()

    print '%s [%s]: Processing %s "%s" with %d processes.' % (
        PROG, datetime.now(), "directory" if is_dir else "filenames in",
        path, proc_count)
    sys.stdout.flush()

    # Create the work queue
    work = JoinableQueue(maxsize=4000)

    # Start the processes
    for proc_num in range(proc_count):
        p = Process(target=load_files, args=(proc_num,))
        p.start()

    # Begin the time on the first file add
    the_time = 0

    # Find files to process
    count = 0

    if is_dir:
        for root, dirs, files in os.walk(path):
            for filename in files:
                basename, ext = os.path.splitext(filename)
                if ext in ['.nt', '.owl', '.rdf']:
                    the_time = the_time or time.time()
                    work.put(os.path.abspath(os.path.join(root, filename)))
                    count += 1
    else:
        with open(path) as the_file:
            for filename in the_file:
                # Strip the newline
                filename = filename[:-1]
                basename, ext = os.path.splitext(filename)
                if ext in ['.nt', '.owl', '.rdf']:
                    the_time = the_time or time.time()
                    work.put(filename)
                    count += 1

    # Add proc_count empty strings to signal the loaders to die
    for proc_num in range(proc_count):
        work.put('')

    # Signal that there is no more work for the queue
    work.close()

    # Wait for all the work to be completed
    work.join()

    # Display the results
    if the_time:
        the_time = time.time() - the_time
    triples = conn.size() - triples
    conn.close()
    print "%s [%s]: %d files, %d triples loaded in %s seconds " \
        " (%s triples/second, %s file commits/second)." % (PROG, datetime.now(),
        count, triples, the_time, triples/the_time, count/the_time)
    sys.stdout.flush()

if __name__ == '__main__':
    main()
