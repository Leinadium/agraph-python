#!/usr/bin/env python2.6
# -*- coding: utf-8 -*-

##***** BEGIN LICENSE BLOCK *****
##Version: MPL 1.1
##
##The contents of this file are subject to the Mozilla Public License Version
##1.1 (the "License"); you may not use this file except in compliance with
##the License. You may obtain a copy of the License at
##http:##www.mozilla.org/MPL/
##
##Software distributed under the License is distributed on an "AS IS" basis,
##WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
##for the specific language governing rights and limitations under the
##License.
##
##The Original Code is the AllegroGraph Java Client interface.
##
##The Original Code was written by Franz Inc.
##Copyright (C) 2006 Franz Inc.  All Rights Reserved.
##
##***** END LICENSE BLOCK *****

"""
Usage: events

An event store stress tests.
"""

from multiprocessing import Process
from Queue import Empty
from datetime import datetime, timedelta
from collections import namedtuple
import os, random, sys, time, traceback

from franz.openrdf.sail.allegrographserver import AllegroGraphServer
from franz.openrdf.query.query import QueryLanguage
from franz.openrdf.repository.repository import Repository
from franz.openrdf.vocabulary import XMLSchema, RDF
from franz.openrdf.model import Literal, Statement, URI

NS = 'http://franz.com/events#';

# Number of worker processes
LOAD_WORKERS = 4
QUERY_WORKERS = 4

# Goal store size
SIZE = (10**9)

# Size of the Events
EVENT_SIZE = 50

# The time to wait in DEQUEUE for the next phase
DEQUEUE_WAIT = 10

LOCALHOST = 'localhost'
AG_HOST = os.environ.get('AGRAPH_HOST', LOCALHOST)
AG_PORT = int(os.environ.get('AGRAPH_PORT', '10035'))
PROG = sys.argv[0]
        
def connect(access_mode=Repository.OPEN):
    """
    Connect is called to connect to a store.
    """
    server = AllegroGraphServer(AG_HOST, AG_PORT, 'test', 'xyzzy')
    catalog = server.openCatalog('tests')
    repository = catalog.getRepository('events_test', access_mode)
    repository.initialize()
    if access_mode is Repository.RENEW:
        repository.registerDatatypeMapping(datatype=XMLSchema.DATETIME, nativeType='datetime')
        repository.registerDatatypeMapping(datatype=XMLSchema.DATE, nativeType='date')
        repository.registerDatatypeMapping(datatype=XMLSchema.INT, nativeType='int')
        repository.registerDatatypeMapping(datatype=XMLSchema.FLOAT, nativeType='float')
    return repository.getConnection()

# PredInfo takes a uri in ntriples format and a generator function
# for the object ntriple string
class PredInfo(namedtuple('PredInfo', 'uri generator')):
    __slots__ = ()

    def __new__(cls, uri, generator):
        assert callable(generator)

        if not isinstance(uri, URI):
            uri = URI(namespace=NS, localname=uri)
        uri = uri.toNTriples()
        
        return tuple.__new__(cls, (uri, generator)) 


# Define some generators
class RandomDate(object):
    def __init__(self, start, end):
        object.__init__(self)
        self.start = start
        self.end = end
        self.seconds = (end - start).days * 24 * 60 * 60

    def random(self):
        return self.start + timedelta(seconds=random.randrange(self.seconds))

BaselineRange = RandomDate(datetime(2008, 1, 1, 0, 0, 0),
                           datetime(2008, 2, 1, 0, 0, 0))
BulkRange = RandomDate(datetime(2008, 2, 1, 0, 0, 0),
                       datetime(2009, 1, 1, 0, 0, 0))
WithQueryRange = RandomDate(datetime(2009, 1, 1, 0, 0, 0),
                            datetime(2009, 2, 1, 0, 0, 0))
DeleteRange = BaselineRange
FullDateRange = RandomDate(datetime(2008, 1, 1, 0, 0, 0),
                           datetime(2009, 2, 1, 0, 0, 0))

def random_datetime():
    fn = random_datetime
    return Literal(fn.range.random()).toNTriples()

random_datetime.range = BaselineRange

def random_date():
    fn = random_datetime
    return Literal(fn.range.random().date()).toNTriples()

def random_int():
    return Literal(random.randrange(2**31-1), XMLSchema.INT).toNTriples()

def random_name():
    fn = random_name
    return Literal(' '.join((random.choice(fn.firsts), random.choice(fn.lasts)))
                   ).toNTriples()

random_name.firsts = ( 'Sam', 'Bruce', 'Mandy', 'Stacy', 'Marcus', 'Susan',
    'Jason', 'Chris', 'Becky', 'Britney', 'David', 'Paul', 'Daniel', 'James',
    'Bradley', 'Amy', 'Tina', 'Brandy', 'Jessica', 'Mary', 'George', 'Jane' )
random_name.lasts = ( 'Smith', 'Jones', 'Flintstones', 'Rubble', 'Jetson',
    'Wayne', 'McFly', 'Stadtham', 'Lee', 'Chan', 'Brown', 'Quinn',
    'Henderson', 'Anderson', 'Roland' )

def random_direction():
    fn = random_direction
    return Literal(random.choice(fn.choices)).toNTriples()

random_direction.choices = ('Inbound', 'Outbound')

def random_bool():
    fn = random_bool
    return Literal(random.choice(fn.choices)).toNTriples()

random_bool.choices = (False, True)

def random_origin():
    fn = random_origin
    return Literal(random.choice(fn.origins)).toNTriples()

random_origin.origins = ('Call Center', 'Sales', 'Front Desk' )

def random_payoption():
    fn = random_payoption
    return Literal(random.choice(fn.options)).toNTriples()

random_payoption.options = ('Cash', 'Credit', 'Money Order')

def random_delivery():
    fn = random_delivery
    return Literal(random.choice(fn.types)).toNTriples()

random_delivery.types = ('Mail', 'FedEx', 'UPS', 'Truck Freight')

def random_money():
    return Literal(round(random.uniform(0.01, 10000.00), 2)).toNTriples()

def random_uri(prefix, limit=int(SIZE/1000)):
    # Striving for 1000 ids per prefix (e.g. customer), so by default there are SIZE/1000 ids
    return URI(namespace=NS,
        localname='%s-%d' % (prefix, random.randrange(limit))).toNTriples()

def random_customer():
    return random_uri('Customer')

def random_account():
    return random_uri('Account')

def random_action():
    fn = random_action
    return Literal(random.choice(fn.actions)).toNTriples()

random_action.actions = ('Add', 'Modify')

def random_handling():
    fn = random_handling
    return Literal(random.choice(fn.handling)).toNTriples()

random_handling.handling = ('Nothing', 'Past Due Notice', 'Collections') 

def type_uri(label):
    return URI(namespace=NS, localname=label).toNTriples()

INTERACTION = [
    PredInfo(RDF.TYPE, lambda: type_uri('CustomerInteraction')),
    PredInfo('EventTimeStamp', random_datetime),
    PredInfo('EntityId', random_int),
    PredInfo('OriginatingSystem', lambda: '"CRM"'),
    PredInfo('Agent', random_name),
    PredInfo('Direction', random_direction),
    PredInfo('DoneInOne', random_bool),
    PredInfo('EndDate', random_datetime),
    PredInfo('FeeBased', random_bool),
    PredInfo('InteractionId', random_int),
    PredInfo('Origin', random_origin),
    PredInfo('PayOption', random_payoption),
    PredInfo('ReasonLevel1', random_int),
    PredInfo('ReasonLevel2', random_int),
    PredInfo('OriginatingSystem', random_int),
    PredInfo('Result', random_int)
    ]

INVOICE = [
    PredInfo(RDF.TYPE, lambda: type_uri('Invoice')),
    PredInfo('EventTimeStamp', random_datetime),
    PredInfo('AccountId', random_account),
    PredInfo('OriginatingSystem', lambda: '"Invoicing"'), 
    PredInfo('DueDate', random_datetime),
    PredInfo('Action', random_action),
    PredInfo('TotalAmountDue', random_money),
    PredInfo('AmountDueHandling', random_handling),
    PredInfo('LegalInvoiceNumber', random_int),
    PredInfo('PreviousBalanceAmount', random_money),
    PredInfo('TotalFinanceActivites', random_money),
    PredInfo('BillDate', random_date),
    PredInfo('TotalUsageCharges', random_money),
    PredInfo('TotalRecurringCharges', random_money),
    PredInfo('TotalOneTimeCharges', random_money)
    ]

PAYMENT = [
    PredInfo(RDF.TYPE, lambda: type_uri('AccountPayment')),
    PredInfo('EventTimeStamp', random_datetime),
    PredInfo('AccountId', random_account),
    PredInfo('OriginatingSystem', lambda: '"Ordering"'),
    PredInfo('SubscriberId', random_customer),
    PredInfo('InvoiceId', random_int),
    PredInfo('PaymentAmount', random_money),
    PredInfo('OriginalAmount', random_money),
    PredInfo('AmountDue', random_money),
    PredInfo('DepositDate', random_datetime),
    PredInfo('PaymentType', random_payoption),
    PredInfo('OriginalPostedAmount', random_money),
    PredInfo('PaymentTarget', lambda: random_uri('PaymentTarget', 100)),
    PredInfo('DepositDesignation', lambda: random_uri('DepositDesignation', 100)),
    PredInfo('BusinessEntity', lambda: random_uri('BusinessUnit', 100))
    ]

PURCHASE = [
    PredInfo(RDF.TYPE, lambda: type_uri('Purchase')),
    PredInfo('EventTimeStamp', random_datetime),
    PredInfo('AccountId', random_account),
    PredInfo('OriginatingSystem', lambda: '"Sales"'),
    PredInfo('PurchaseDate', random_datetime),
    PredInfo('PurchaseAmount', random_money),
    PredInfo('InvoiceID', random_int),
    PredInfo('ProductID', lambda: random_uri('Product')), 
    PredInfo('LegalInvoiceNumber', random_int),
    PredInfo('PreviousBalanceAmount', random_money),
    PredInfo('DeliveredVia', random_delivery),
    PredInfo('PaidVia', random_payoption),
    PredInfo('CCApprovalNumber', random_int),
    PredInfo('TotalRecurringCharges', random_money),
    PredInfo('TotalOneTimeCharges', random_money)
    ]

def pad_events(event):
    pred_format = event[0].generator() + '-%d'

    for i in range(len(event), EVENT_SIZE):
        event.append(PredInfo(pred_format % i, random_int))

    assert len(event) == EVENT_SIZE

    return event

EVENTS = map(pad_events, [INTERACTION, INVOICE, PAYMENT, PURCHASE])

def random_event(conn, storage):
    event = random.choice(EVENTS)

    # A customer URI for the quad's graph
    customer = random_customer()

    # Groups the event triples via an anonymous node
    bnode = conn.createBNode().toNTriples()

    for index, info in enumerate(event):
        storage[index] = [bnode, info.uri, info.generator(), customer]

    return storage

def buggy_version():
    """There is a bug in Python versions <= 2.6.2"""
    return map(int, sys.version.split()[0].split('.')) <= [2, 6, 2]

if buggy_version():
    from multiprocessing.queues import JoinableQueue as BadJoinableQueue
    class JoinableQueue(BadJoinableQueue):
        def put(self, obj, block=True, timeout=None):
            assert not self._closed
            if not self._sem.acquire(block, timeout):
                raise Full

            self._notempty.acquire()
            self._cond.acquire()
            try:
                if self._thread is None:
                    self._start_thread()
                self._buffer.append(obj)
                self._unfinished_tasks.release()
                self._notempty.notify()
            finally:
                self._cond.release()
                self._notempty.release()
else:
    from multiprocessing import JoinableQueue

# The work queue
class LoadPhase:
    baseline, bulk, with_query, delete = range(4)

class PhaseParameters(object):
    def __init__(self, date_range, events_in_commit, triples):
        random_datetime.range = date_range
        object.__init__(self)
        self.events_in_commit = events_in_commit
        self.triples = triples

    @property
    def commits(self):
        return int(self.triples / (self.events_in_commit * EVENT_SIZE))

    @property
    def commits_per_worker(self):
        return int(self.commits / LOAD_WORKERS)

loadq = None
queryq = None

def load_events(proc_num):
    """
    load_files does the work of the child processes.
    """
    conn = None
    
    def dequeue():
        try:
            return loadq.get(timeout=DEQUEUE_WAIT)
        except Empty:
            return None

    def load_phase(params):
        storage = [None]*EVENT_SIZE
        quads = [None]*(EVENT_SIZE*params.events_in_commit)

        count = 0
        errors = 0

        for commit in range(params.commits_per_worker):
            index = 0
            for event in range(params.events_in_commit):
                event_quads = random_event(conn, storage)
                quads[index:index+EVENT_SIZE] = event_quads
                index += EVENT_SIZE

            try:
                conn.mini_repository.addStatements(quads)
                count += len(quads)
            except Exception:
                print '%s(%d) [%s]: Error adding quads...' % (
                    PROG, proc_num, datetime.now())
                errors += 1
                traceback.print_exc()
            
        print '%s(%d) [%s]: Loading finished, %d triples loaded at %s triples ' \
            'per commit, %d loading errors.' % (PROG, proc_num, datetime.now(),
            count, EVENT_SIZE*params.events_in_commit, errors)
        sys.stdout.flush()
        loadq.task_done()

    def delete_phase():
        # Replace this with an in-server deletion
        the_range = conn.createRange(DeleteRange.start, DeleteRange.end)
        timestamp = URI(namespace=NS, localname='EventTimeStamp')

        queryString = """
            (select0 (?event)
                (lisp ?start (value->upi \"%s\" :date-time))
                (lisp ?end (value->upi \"%s\" :date-time))
                (q- ?event !%s (? ?start ?end))
                (lisp (delete-triples :s ?event)))""" % (
                    the_range.getLowerBound().getLabel(),
                    the_range.getUpperBound().getLabel(),
                    timestamp.toNTriples())

        print queryString

        with conn.session():
            events = len(conn.prepareTupleQuery(QueryLanguage.PROLOG, queryString).evaluate())
            print '%s(%d) [%s]: Found %d events (%d triples) to delete.' % (PROG, proc_num,
                datetime.now(), events, events * EVENT_SIZE)
            conn.commit()

##         # A python version?
##         events = conn.getStatements(None, timestamp, the_range)
##         print '%s(%d) [%s]: Found %d events to delete.' % (PROG, proc_num,
##             datetime.now(), len(events))
##         for event in events:
##             conn.removeTriples(event.getSubject(), None, None)
##         conn.commit()
            
        loadq.task_done()

    with connect().session(True) as conn:
        phase = dequeue()
        assert phase == LoadPhase.baseline
        load_phase(PhaseParameters(BaselineRange, 1, SIZE/10))
        
        phase = dequeue()
        assert phase == LoadPhase.bulk
        load_phase(PhaseParameters(BulkRange, 400, (SIZE*9)/10))

        phase = dequeue()
        assert phase == LoadPhase.with_query
        load_phase(PhaseParameters(WithQueryRange, 1, SIZE/10))

        phase = dequeue()
        if phase == LoadPhase.delete:
            delete_phase()

    conn.close()

def query_events(proc_num):
    conn = connect()

    def dequeue():
        try:
            return queryq.get_nowait()
        except Empty:
            return None

    timestamp = URI(namespace=NS, localname='EventTimeStamp')

    def random_query():
        # Pick a random customer
        customer = random_customer()

        # Pick a random date range
        start, end = FullDateRange.random(), FullDateRange.random()
        if start > end:
            start, end = end, start

        the_range = conn.createRange(start, end)

        # Perform the query
        events = conn.getStatements(None, timestamp, the_range, contexts=customer)
        
        return len(events)

    the_time = time.time()
    queries = 0
    count = 0
    while dequeue() is None:
        count += random_query()
        queries += 1

    conn.close()
    queryq.task_done()

    the_time = time.time() - the_time
    print 'query(%d) [%s]: Querying finished. %d triple results returned for %d ' \
        'queries in %d seconds (%s queries/second), ' % (
        proc_num, datetime.now(), count, queries, the_time, queries/the_time)
    sys.stdout.flush()

def main():
    """
    The parent main process.
    """
    global loadq

    # Renewing the repository
    print '%s [%s]: Renewing the repository.' % (PROG, datetime.now())
    conn = connect(Repository.RENEW)
    triples = conn.size()

    print '%s [%s]: Processing events with %d loading, %d querying processes.' % (
        PROG, datetime.now(), LOAD_WORKERS, QUERY_WORKERS)

    # Create the work queue
    loadq = JoinableQueue(maxsize=LOAD_WORKERS)

    # Start the loading processes
    for proc_num in range(LOAD_WORKERS):
        p = Process(target=load_events, args=(proc_num,))
        p.start()

    def load_phase(phase):
        # Begin the timer
        phase_time = time.time()
        triples_start = conn.size()

        # Tell the processes what to do (We only need one deletion process)
        proc_count = 1 if phase == LoadPhase.delete else LOAD_WORKERS
        for proc_num in range(proc_count):
            loadq.put(phase)

        # Wait for all the work to be completed
        loadq.join()

        triples_end = conn.size()
        triples = triples_end - triples_start
        phase_time = time.time() - phase_time 
        print '%s [%s]: %d total triples processed in %s seconds ' \
            ' (%s triples/second). ' % (PROG, datetime.now(),
            triples, phase_time, triples/phase_time),
        print 'Store contains %d triples.' % triples_end
        sys.stdout.flush()

    def begin_queries():
        global queryq
        queryq = JoinableQueue(maxsize=QUERY_WORKERS)
        
        # Start the query processes
        for proc_num in range(QUERY_WORKERS):
            p = Process(target=query_events, args=(proc_num,))
            p.start()

    def end_queries():
        for proc_num in range(QUERY_WORKERS):
            queryq.put('Stop')

        queryq.join()

    total_time = time.time()
    print '%s [%s]: Phase 1: Baseline %d triple commits without queries.' % (
        PROG, datetime.now(), EVENT_SIZE)
    sys.stdout.flush()
    load_phase(LoadPhase.baseline)

    print '%s [%s]: Phase 2: Grow store to about %d triples.' % (
        PROG, datetime.now(), SIZE)
    sys.stdout.flush()
    load_phase(LoadPhase.bulk)

    print '%s [%s]: Phase 3: Perform %d triple commits while running queries.' % (
        PROG, datetime.now(), EVENT_SIZE)
    sys.stdout.flush()
    begin_queries()
    load_phase(LoadPhase.with_query)

    print '%s [%s]: Phase 4: Shrink store by 1 month while running queries.' % (
        PROG, datetime.now())
    sys.stdout.flush()
    load_phase(LoadPhase.delete)
    end_queries()
    
    # Display the results
    total_time = time.time() - total_time
    triples = conn.size() - triples
    conn.close()

    print '%s [%s]: Test completed in %s total seconds - ' \
        'store contains %d triples.' % (PROG, datetime.now(),
        total_time, triples)
    sys.stdout.flush()


if __name__ == '__main__':
    main()
